{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from src.modified_diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from diffusers import AutoencoderKL, StableDiffusionPipeline\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path='/mnt/d/repos/stable-diffusion-webui/models/Stable-diffusion/realdosmix_.safetensors'\n",
    "pipe = StableDiffusionPipeline.from_ckpt(ckpt_path)\n",
    "pipe.vae = AutoencoderKL.from_pretrained('lint/anime_vae')\n",
    "\n",
    "#pipe = StableDiffusionPipeline.from_pretrained('lint/simpathizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet_path = '/mnt/d/repos/style_controlnet/models/realdosmix__animestyler2/checkpoint-10000'\n",
    "\n",
    "pipe = StableDiffusionControlNetPipeline(\n",
    "    **pipe.components,\n",
    "    controlnet = ControlNetModel.from_pretrained(controlnet_path)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.controlnet = ControlNetModel.from_pretrained(\"../models/realdosmix__animestyler2/checkpoint-15401\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.feature_extractor = None\n",
    "pipe.safety_checker = None\n",
    "pipe.requires_safety_checker = False\n",
    "#pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "for component in pipe.components.values():\n",
    "    if isinstance(component, torch.nn.Module):\n",
    "        component.to('cuda', torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt from https://civitai.com/gallery/76860, https://civitai.com/gallery/76862\n",
    "prompt = \"best quality, masterpiece,Dark hair, dark eyes, upper body, sun flare, outdoors, mountain, valley, sky. clouds, smiling\"\n",
    "negative_prompt = \"(low quality, worst quality:1.4)\"\n",
    "controlnet_prompt = prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.schedulers import EulerAncestralDiscreteScheduler\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_pretrained('runwayml/stable-diffusion-v1-5', subfolder='scheduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning_scales = np.linspace(0, 1, 51)\n",
    "#conditioning_scales = [0.0, 0.5, 1.0]\n",
    "output_dir = '../archive/mountains'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for cond_scale in conditioning_scales:\n",
    "    result = pipe(\n",
    "        prompt=prompt, \n",
    "        generator=torch.Generator().manual_seed(3283666171), \n",
    "        controlnet_conditioning_scale=cond_scale,\n",
    "        guidance_scale=11,\n",
    "        num_inference_steps=20,\n",
    "        negative_prompt=negative_prompt,\n",
    "        controlnet_prompt=controlnet_prompt,\n",
    "        height=768,\n",
    "    )\n",
    "\n",
    "    result.images[0].save(f'{output_dir}/conditioning_scale_{np.around(cond_scale,2)}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gif\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "output_dir = '../archive/brown_eyes'\n",
    "save_dir = '../archive'\n",
    "resolution = (256, 256)\n",
    "\n",
    "frames = [Image.open(image).resize(resolution) for image in sorted(glob(f\"{output_dir}/*.png\"))]\n",
    "\n",
    "frames[0].save(f\"{save_dir}/brown_eyes.gif\", format=\"GIF\", append_images=frames+frames[::-1],\n",
    "               save_all=True, duration=int(1000/15), loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image grid\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "\n",
    "images = []\n",
    "image_dir = output_dir\n",
    "\n",
    "for image_path in sorted(Path(image_dir).glob('*.?.png')):\n",
    "    images.append(read_image(str(image_path)))\n",
    "\n",
    "grid = make_grid(images, nrow=11)\n",
    "grid = grid.permute(1,2,0).numpy()\n",
    "image_grid = Image.fromarray(grid)\n",
    "image_grid.save(Path(image_dir).parent/f'{Path(output_dir).name}_grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbbcdde725e9a65f1cb734ac4223fed46e03daf1eb62d8ccb3c48face3871521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
